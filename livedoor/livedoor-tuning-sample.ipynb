{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from jubatus.common import Datum\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from embedded_jubatus import Classifier\n",
    "\n",
    "# データを読み込んでdataframeを作る\n",
    "categories = [f for f in os.listdir(\"text\") if os.path.isdir(os.path.join(\"text\", f))]\n",
    "print(categories)\n",
    "articles = []\n",
    "for c in categories:\n",
    "    articles = articles + [(c, os.path.join(\"text\", c, t)) for t in os.listdir(os.path.join(\"text\", c)) if t != \"LICENSE.txt\"]\n",
    "df = pd.DataFrame(articles, columns=[\"target\", \"data\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datumのリストを作成しておく\n",
    "datum_list = []\n",
    "for d in df[\"data\"]:\n",
    "    dt = Datum()\n",
    "    with open(d) as f:\n",
    "        l = f.readlines()\n",
    "        doc = l[2].rstrip()\n",
    "        dt.add_string(\"title\", doc) # Datumにテキストデータを追加\n",
    "    datum_list.append(dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練用、テスト用にデータセットをわける\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"data\"], df[\"target\"], random_state=42, stratify=df[\"target\"])\n",
    "num_splits = 4\n",
    "\n",
    "# 交差検証の準備\n",
    "kf = StratifiedKFold(n_splits=num_splits, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jubatusの準備\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" }\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 1.0\n",
    "    },\n",
    "    \"method\" : \"AROW\"\n",
    "}\n",
    "cl = Classifier(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差検証実行用の関数\n",
    "def do_cv(cl, n=3):\n",
    "    random.seed(42)\n",
    "    y_cv_results = []\n",
    "    for fold, indexes in enumerate(kf.split(X_train.index, y_train)):\n",
    "        cl.clear()\n",
    "        train_index, test_index = indexes\n",
    "\n",
    "        # (ラベル, Datum)のリストを作る\n",
    "        training_data = [(df[\"target\"][X_train.index[i]], datum_list[X_train.index[i]]) for i in train_index]\n",
    "\n",
    "        # Jubatusに学習させる\n",
    "        for i in range(n):\n",
    "            cl.train(training_data)\n",
    "\n",
    "        test_data = [datum_list[X_train.index[i]] for i in test_index]\n",
    "\n",
    "        # Jubatusに分類させる\n",
    "        result = cl.classify(test_data)\n",
    "\n",
    "        # 分類スコアが最大のラベルを予測結果として取り出す\n",
    "        y_pred = [max(x, key=lambda y:y.score).label  for x in result]\n",
    "\n",
    "        # 正解を取り出す\n",
    "        y = [df[\"target\"][X_train.index[i]] for i in test_index]\n",
    "\n",
    "        y_cv_results.append([y, y_pred])\n",
    "    y_sum = []\n",
    "    y_pred_sum = []\n",
    "    for y, y_pred in y_cv_results:\n",
    "        y_sum.extend(y)\n",
    "        y_pred_sum.extend(y_pred)\n",
    "    print(classification_report(y_sum, y_pred_sum, digits=4))\n",
    "    print(confusion_matrix(y_sum, y_pred_sum))\n",
    "\n",
    "# ホールドアウト検証実行用の関数\n",
    "def do_holdout(cl, n):\n",
    "    random.seed(42)\n",
    "    training_data = [(df[\"target\"][i], datum_list[i]) for i in X_train.index]\n",
    "    test_data = [datum_list[i] for i in X_test.index]\n",
    "    y_true = [df[\"target\"][i] for i in X_test.index]\n",
    "\n",
    "    for i in range(n):\n",
    "        cl.train(training_data)\n",
    "    result = cl.classify(test_data)\n",
    "    y_pred = [max(x, key=lambda y:y.score).label  for x in result]\n",
    "\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cv(cl, 1)\n",
    "do_holdout(cl, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繰り返し学習\n",
    "do_cv(cl, 2)\n",
    "do_cv(cl, 3)\n",
    "do_cv(cl, 4)\n",
    "do_cv(cl, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書の変更\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                   \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/mecab-ipadic-neologd/\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" }\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 1.0\n",
    "    },\n",
    "    \"method\" : \"AROW\"\n",
    "}\n",
    "cl = Classifier(config)\n",
    "do_cv(cl, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi-gramの追加\n",
    "\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                },\n",
    "                \"mecab-bi\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"2\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\" \n",
    "                }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" },\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab-bi\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" }\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 1.0\n",
    "    },\n",
    "    \"method\" : \"AROW\"\n",
    "}\n",
    "cl = Classifier(config)\n",
    "do_cv(cl, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idfの利用\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                },\n",
    "            \"mecab-bi\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"2\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"                \n",
    "            }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"tf\", \"global_weight\" : \"idf\" },\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab-bi\", \"sample_weight\" : \"tf\", \"global_weight\" : \"idf\" }\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 1.0\n",
    "    },\n",
    "    \"method\" : \"AROW\"\n",
    "}\n",
    "cl = Classifier(config)\n",
    "do_cv(cl, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アルゴリズム選択、パラメータチューニング\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                },\n",
    "            \"mecab-bi\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"2\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"                \n",
    "            }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" },\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab-bi\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" }\n",
    "\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 1.0\n",
    "    },\n",
    "    \"method\" : \"AROW\"\n",
    "}\n",
    "\n",
    "reg = [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "algorithms = [\"CW\", \"AROW\"]\n",
    "for alg in algorithms:\n",
    "    for r in reg:\n",
    "        print(alg, r)\n",
    "        config[\"parameter\"][\"regularization_weight\"] = r\n",
    "        config[\"method\"] = alg\n",
    "        cl = Classifier(config)\n",
    "        do_cv(cl, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COTOHA API利用のための関数の作成\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "# 下記の情報はCOTOHA API Portalにログインすると確認できます。\n",
    "CLIENT_SECRET = \"CLIENT SECRETを入れる\"\n",
    "CLIENT_ID = \"CLIENT IDを入れる\"\n",
    "TOKEN_URL = \"TOKEN_URLを入れる\"\n",
    "API_BASE = \"API_BASEを入れる\"\n",
    "\n",
    "def  get_token():\n",
    "    \"\"\"トークン認証を行う\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"charset\": \"UTF-8\"\n",
    "    }\n",
    "    data = {\n",
    "        \"grantType\": \"client_credentials\",\n",
    "        \"clientId\": CLIENT_ID,\n",
    "        \"clientSecret\": CLIENT_SECRET\n",
    "    }\n",
    "    r = requests.post(TOKEN_URL, headers=headers, data=json.dumps(data))\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def parse(text, token):\n",
    "    \"\"\"構文解析を実行する\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"charset\": \"UTF-8\",\n",
    "        \"Authorization\": \"Bearer {}\".format(token)\n",
    "    }\n",
    "    data = {\n",
    "        \"sentence\": text,\n",
    "        \"type\": \"default\"\n",
    "    }\n",
    "    r = requests.post(API_BASE + \"v1/parse\", headers=headers, data=json.dumps(data))\n",
    "    if r.json()[\"status\"] != 0:\n",
    "        print(r.json()[\"status\"], text)\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def ne(text, token):\n",
    "    \"\"\"固有表現抽出を行う\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"charset\": \"UTF-8\",\n",
    "        \"Authorization\": \"Bearer {}\".format(token)\n",
    "    }\n",
    "    data = {\n",
    "        \"sentence\": text,\n",
    "        \"type\": \"default\",\n",
    "        \"dic_type\": []\n",
    "    }\n",
    "    r = requests.post(API_BASE + \"v1/ne\", headers=headers, data=json.dumps(data))\n",
    "    if r.json()[\"status\"] != 0:\n",
    "        print(r.json()[\"status\"], text)\n",
    "    return r.json()\n",
    "\n",
    "TOKEN = get_token()[\"access_token\"]\n",
    "text = \"週末映画まとめ読み】 『モテキ』初登場2位でトップ3を邦画が独占＜10月1日号＞\"\n",
    "print(json.dumps(parse(text, TOKEN), indent=2, ensure_ascii=False))\n",
    "print(json.dumps(ne(text, TOKEN), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COTOHA APIの解析結果を用いる特徴抽出の準備\n",
    "\n",
    "def get_tokens(result):\n",
    "    tokens = []\n",
    "    for r in result:\n",
    "        for t in r[\"tokens\"]:\n",
    "            tokens.append(t)\n",
    "    return tokens\n",
    "\n",
    "def make_datum_list_with_cotoha(df, add_lemma=False,\n",
    "                                add_ne_form=False, ne_filter=[]):\n",
    "    datum_list = []\n",
    "    for d in df[\"data\"]:\n",
    "        dt = Datum()\n",
    "        with open(d) as f:\n",
    "            l = f.readlines()\n",
    "            doc = l[2].rstrip()\n",
    "            dt.add_string(\"title\", doc) # Datumにテキストデータを追加\n",
    "    \n",
    "        parse_file = d.replace(\"text\", \"parse_title\").replace(\"txt\", \"json\")\n",
    "        ne_file = d.replace(\"text\", \"ne_title\").replace(\"txt\", \"json\")\n",
    "        with open(parse_file) as f, open(ne_file) as ne:\n",
    "            j = json.load(f)\n",
    "            ne_j = json.load(ne)\n",
    "            tokens = get_tokens(j[\"result\"])\n",
    "            \n",
    "            # 固有表現を入れる\n",
    "            for r in ne_j[\"result\"]:\n",
    "                if add_ne_form:\n",
    "                    if ne_filter:\n",
    "                        if r[\"class\"] in ne_filter:\n",
    "                            dt.add_number(\"ne-{}\".format(r[\"form\"]), 1.0)                            \n",
    "                    else:\n",
    "                        dt.add_number(\"ne-{}\".format(r[\"form\"]), 1.0)\n",
    "\n",
    "            # token情報からlemmaを取得\n",
    "            for r in j[\"result\"]:\n",
    "                for t in r[\"tokens\"]:\n",
    "                    k = \"lemma-{}\".format(t[\"lemma\"])\n",
    "                    v = 1.0\n",
    "                    if add_lemma:\n",
    "                        dt.add_number(k, v)\n",
    "        datum_list.append(dt)\n",
    "    print(len(datum_list))\n",
    "    return datum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmaのみを利用\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                },\n",
    "            \"mecab-bi\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"2\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"                \n",
    "            }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" },\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab-bi\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" }\n",
    "\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 0.5\n",
    "    },\n",
    "    \"method\" : \"CW\"\n",
    "}\n",
    "cl = Classifier(config)\n",
    "datum_list = make_datum_list_with_cotoha(df, add_lemma=True)\n",
    "do_cv(cl, 3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固有表現も追加\n",
    "datum_list = make_datum_list_with_cotoha(\n",
    "    df, add_lemma=True,\n",
    "    add_ne_form=True, ne_filter=set([\"ORG\", \"PSN\", \"LOC\", \"ART\"]))\n",
    "\n",
    "do_cv(cl, 3) # jubatusは CW:0.5 で動作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アルゴリズム選択、パラメータチューニング\n",
    "reg = [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "algorithms = [\"CW\", \"AROW\"]\n",
    "for alg in algorithms:\n",
    "    for r in reg:\n",
    "        print(alg, r)\n",
    "        config[\"parameter\"][\"regularization_weight\"] = r\n",
    "        config[\"method\"] = alg\n",
    "        cl = Classifier(config)\n",
    "        do_cv(cl, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ホールドアウト検証\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                },\n",
    "            \"mecab-bi\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/TkrUdagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"2\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"                \n",
    "            }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" },\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab-bi\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" }\n",
    "\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 0.5\n",
    "    },\n",
    "    \"method\" : \"CW\"\n",
    "}\n",
    "cl = Classifier(config)\n",
    "do_holdout(cl, 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
