{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "categories = [f for f in os.listdir(\"text\") if os.path.isdir(os.path.join(\"text\", f))]\n",
    "print(categories)\n",
    "articles = []\n",
    "for c in categories:\n",
    "    articles = articles + [(c, os.path.join(\"text\", c, t)) for t in os.listdir(os.path.join(\"text\", c)) if t != \"LICENSE.txt\"]\n",
    "df = pd.DataFrame(articles, columns=[\"target\", \"data\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jubatus.common import Datum\n",
    "\n",
    "datum_list = []\n",
    "for d in df[\"data\"]:\n",
    "    dt = Datum()\n",
    "    with open(d) as f:\n",
    "        l = f.readlines()\n",
    "        doc = l[2].rstrip()\n",
    "        dt.add_string(\"title\", doc) # Datumにテキストデータを追加\n",
    "    datum_list.append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from embedded_jubatus import Classifier\n",
    "\n",
    "config = {\"converter\" : {\n",
    "        \"string_filter_types\" : {},\n",
    "        \"string_filter_rules\" : [],\n",
    "        \"num_filter_types\" : {},\n",
    "        \"num_filter_rules\" : [],\n",
    "        \"string_types\": {\n",
    "                \"mecab\": {\n",
    "                    \"method\": \"dynamic\",\n",
    "                    \"path\": \"libmecab_splitter.so\",\n",
    "                    \"function\": \"create\",\n",
    "                    \"arg\": \"-d /home/udagawa/local/lib/mecab/dic/ipadic\",\n",
    "                    \"ngram\": \"1\",\n",
    "                    \"base\": \"true\",\n",
    "                    \"include_features\": \"*\",\n",
    "                    \"exclude_features\": \"\"\n",
    "                }\n",
    "        },\n",
    "        \"string_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"mecab\", \"sample_weight\" : \"bin\", \"global_weight\" : \"bin\" }\n",
    "        ],\n",
    "        \"num_types\" : {},\n",
    "        \"num_rules\" : [\n",
    "            { \"key\" : \"*\", \"type\" : \"num\" }\n",
    "        ]\n",
    "    },\n",
    "    \"parameter\" : {\n",
    "        \"regularization_weight\" : 1.0\n",
    "    },\n",
    "    \"method\" : \"AROW\"\n",
    "}\n",
    "cl = Classifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "# 訓練用、テスト用にデータセットをわける\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"data\"], df[\"target\"], random_state=42, stratify=df[\"target\"])\n",
    "num_splits = 4\n",
    "# 交差検証の準備\n",
    "kf = StratifiedKFold(n_splits=num_splits, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "random.seed(42)\n",
    "y_cv_results = []\n",
    "for fold, indexes in enumerate(kf.split(X_train.index, y_train)):\n",
    "    cl.clear()\n",
    "    train_index, test_index = indexes\n",
    "\n",
    "    # (ラベル, Datum)のリストを作る\n",
    "    training_data = [(df[\"target\"][X_train.index[i]], datum_list[X_train.index[i]]) for i in train_index]\n",
    "\n",
    "    # Jubatusに学習させる\n",
    "    cl.train(training_data)\n",
    "\n",
    "    test_data = [datum_list[X_train.index[i]] for i in test_index]\n",
    "\n",
    "    # Jubatusに分類させる\n",
    "    result = cl.classify(test_data)\n",
    "\n",
    "    # 分類スコアが最大のラベルを予測結果として取り出す\n",
    "    y_pred = [max(x, key=lambda y:y.score).label  for x in result]\n",
    "\n",
    "    # 正解を取り出す\n",
    "    y = [df[\"target\"][X_train.index[i]] for i in test_index]\n",
    "\n",
    "    y_cv_results.append([y, y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_sum = []\n",
    "y_pred_sum = []\n",
    "for y, y_pred in y_cv_results:\n",
    "    y_sum.extend(y)\n",
    "    y_pred_sum.extend(y_pred)\n",
    "print(classification_report(y_sum, y_pred_sum))\n",
    "print(confusion_matrix(y_sum, y_pred_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.clear()\n",
    "training_data = [(df[\"target\"][i], datum_list[i]) for i in X_train.index]\n",
    "test_data = [datum_list[i] for i in X_test.index]\n",
    "y_test = [df[\"target\"][i] for i in X_test.index]\n",
    "cl.train(training_data)\n",
    "r = cl.classify(test_data)\n",
    "\n",
    "y_pred = [max(x, key=lambda y:y.score).label  for x in r]\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.save(\"livedoor_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "jubadump -i /tmp/127.0.0.1_0_classifier_livedoor_title.jubatus > title_weights.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "j = json.load(open(\"title_weights.json\"))\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "weights = {k:[] for k in categories}\n",
    "index = []\n",
    "for w in j[\"storage\"][\"storage\"][\"weight\"]:\n",
    "    k = re.search(r\"\\$.+@\", w).group(0).replace(\"$\", \"\").replace(\"@\", \"\")\n",
    "    index.append(k)\n",
    "    for label in categories:\n",
    "        try:\n",
    "            weights[label].append(j[\"storage\"][\"storage\"][\"weight\"][w][label][\"v1\"])\n",
    "        except KeyError:\n",
    "            weights[label].append(0)\n",
    "d = pd.DataFrame(weights, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categories:\n",
    "    print(c)\n",
    "    print(\"positive feature\")\n",
    "    print(d[c].sort_values(ascending=False)[:3])\n",
    "    print(\"\")\n",
    "    print(\"negative feature\")\n",
    "    print(d[c].sort_values()[:3])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
